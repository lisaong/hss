{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensor Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse raw sensor data from PhysioNet: https://physionet.org/physiobank/database/noneeg/\n",
    "\n",
    "Data: \"Bag of Sensors\"\n",
    "\n",
    "Feature Extraction\n",
    "- Statistical\n",
    "- Continuous\n",
    "- Spectral\n",
    "\n",
    "Modeling"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This database contains non-EEG physiological signals collected at Quality of Life Laboratory at University of Texas at Dallas, used to infer the neurological status (including physical stress, cognitive stress, emotional stress and relaxation) of 20 healthy subjects. \n",
    "\n",
    "The data was collected using non-invasive wrist worn biosensors and consists of electrodermal activity (EDA), temperature, acceleration, heart rate (HR), and arterial oxygen level (SpO2)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The experimental procedures involving human subjects described in this work were approved under UTD IRB # 12-29 by the Institutional Review Board at the University of Texas at Dallas, Richardson, Texas, USA.\n",
    "\n",
    "The dataset consists of 7 stages for 20 subjects:\n",
    "\n",
    "First Relaxation: five minutes\n",
    "\n",
    "Physical Stress: Stand for one minute, walk on a treadmill at one mile per hour for two minutes, then walk/jog on the treadmill at three miles per hour for two minutes.\n",
    "\n",
    "Second Relaxation: five minutes.\n",
    "\n",
    "Mini-emotional stress*: 40 seconds (Note: This portion of the data, which was collected right before the cognitive stress task, is not explained in the paper.) During this 40 seconds, the “instructions” for the math portion of the cognitive stress (to count backwards by sevens, beginning with 2485, for three minutes) were read to the volunteer.\n",
    "\n",
    "Cognitive Stress: Count backwards by sevens, beginning with 2485, for three minutes. Next, perform the Stroop test for two minutes. The volunteer was alerted to errors by a buzzer. The Stroop test consisted of reading the names of colors written in a different color ink, then saying what color the ink was.\n",
    "\n",
    "Third Relaxation: five minutes.\n",
    "\n",
    "Emotional Stress: The volunteer was told he/she would be shown a five minute clip from a horror movie in one minute. After the minute of anticipation, a clip from a zombie apocalypse movie, The Horde was shown.\n",
    "\n",
    "Forth Relaxation: five minutes.\n",
    "\n",
    "*Note: We had not originally intended to count the reading of the instructions to count backwards as an emotional stress. After all, instructions were given for each of the tasks. Unlike the other instruction sets, however, this one created a stress response in many of the volunteers that was obvious to the test administrator as the test was being given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Each subject has several datafiles:\n",
    "- SubjectN_AccTempEDA.atr: annotation\n",
    "- SubjectN_AccTempEDA.dat: data\n",
    "- SubjectN_AccTempEDA.hea: header\n",
    "- SubjectN_Sp02HR.dat: data\n",
    "- SubjectN_Sp02HR.hea: header\n",
    "\n",
    "These files are in the WFDB format, and can be read using the `wfdb` python module.\n",
    "(https://github.com/MIT-LCP/wfdb-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "# pip install wfdb\n",
    "import wfdb\n",
    "\n",
    "# render plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acc Temp EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = wfdb.rdann('./data/physionet/Subject10_AccTempEDA', extension='atr', summarize_labels=True)\n",
    "print(ann.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_acc_temp_eda = wfdb.rdrecord('./data/physionet/Subject10_AccTempEDA')\n",
    "print(record_acc_temp_eda.__dict__)\n",
    "\n",
    "wfdb.plot_wfdb(record=record_acc_temp_eda, title='Subject10_AccTempEDA', annotation=ann, plot_sym=True, \n",
    "               time_units='seconds', figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_acc_temp_eda = record_acc_temp_eda.p_signal\n",
    "data_acc_temp_eda.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpO2 HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_spo2_hr = wfdb.rdrecord('./data/physionet/Subject10_SpO2HR')\n",
    "print(record_spo2_hr.__dict__)\n",
    "\n",
    "wfdb.plot_wfdb(record=record_spo2_hr, title='Subject10_SpO2HR', time_units='seconds', figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_spo2_hr = record_spo2_hr.p_signal\n",
    "data_spo2_hr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of acceleration, etc samples per second\n",
    "record_acc_temp_eda.fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of SpO2 and HR samples per second\n",
    "record_spo2_hr.fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning data of different frequencies\n",
    "\n",
    "The two dataset frequencies (number of samples per second) are different.\n",
    "\n",
    "To support processing both datasets at the same time, we need to match the frequencies.\n",
    "\n",
    "This is a common situation when taking readings from different sensors or data sources.\n",
    "\n",
    "Two strategies:\n",
    "1. Upsampling the smaller frequency data. E.g: repeat samples or interpolate.\n",
    "2. Downsampling the larger frequency data. E.g: replace with mean or median.\n",
    "\n",
    "Which one to pick depends on requirements: whether you need to maintain precision of the higher frequency dataset.\n",
    "\n",
    "Example: https://machinelearningmastery.com/resample-interpolate-time-series-data-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling SpO2 HR to 8 samples per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an index with 1 second timestamps, using the length of data_spo2_hr\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.period_range.html\n",
    "\n",
    "# for this dataset, the start date is just an arbitrary reference\n",
    "per_second_index = pd.period_range(start='2019-01-01', periods=len(data_spo2_hr), freq='S')\n",
    "per_second_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe for SpO2 data using the above period index\n",
    "df_spO2_hr = pd.DataFrame(data_spo2_hr, index=per_second_index, columns=record_spo2_hr.sig_name)\n",
    "df_spO2_hr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample to match the frequency of the other data (8 times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = record_acc_temp_eda.fs / record_spo2_hr.fs\n",
    "factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample, then interpolate\n",
    "# Note: whether interpolation makes sense depends on the sensor and type of data\n",
    "upsampled = df_spO2_hr.resample('125ms')\n",
    "\n",
    "df_upsampled = upsampled.interpolate()\n",
    "df_upsampled.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upsampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: there are fewer values in the Acc dataframe, so we need to ignore the\n",
    "# later entries from df_upsampled.\n",
    "\n",
    "df_acc_temp_eda = pd.DataFrame(data_acc_temp_eda, columns=record_acc_temp_eda.sig_name)\n",
    "df_acc_temp_eda.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_temp_eda.index = df_spO2_hr_upsampled.index[:len(data_acc_temp_eda)]\n",
    "df_acc_temp_eda.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the two dataframes, column-wise\n",
    "df = pd.concat([df_acc_temp_eda, df_spO2_hr_upsampled], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean() # mean of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.median() # median is less sensitive to outliers than mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.std() # standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretise into quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ax.values.ravel() # raw values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ax_q10'] = pd.qcut(df.ax.values.ravel(), 10, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "df['ax_q10'].plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram showing distribution in the 10 levels\n",
    "df['ax_q10'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ay_q10'] = pd.qcut(df.ay.values.ravel(), 10, labels=False)\n",
    "df['az_q10'] = pd.qcut(df.az.values.ravel(), 10, labels=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
