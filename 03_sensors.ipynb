{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensor Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse \"Bag of sensors\" data from PhysioNet: https://physionet.org/physiobank/database/noneeg/\n",
    "\n",
    "Under/Oversampling\n",
    "\n",
    "Feature Extraction\n",
    "- Statistical\n",
    "- Spectral\n",
    "\n",
    "Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Introduction"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This database contains non-EEG physiological signals collected at Quality of Life Laboratory at University of Texas at Dallas, used to infer the neurological status (including physical stress, cognitive stress, emotional stress and relaxation) of 20 healthy subjects. \n",
    "\n",
    "The data was collected using non-invasive wrist worn biosensors and consists of electrodermal activity (EDA), temperature, acceleration, heart rate (HR), and arterial oxygen level (SpO2)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The experimental procedures involving human subjects described in this work were approved under UTD IRB # 12-29 by the Institutional Review Board at the University of Texas at Dallas, Richardson, Texas, USA.\n",
    "\n",
    "The dataset consists of 7 stages for 20 subjects:\n",
    "\n",
    "First Relaxation: five minutes\n",
    "\n",
    "Physical Stress: Stand for one minute, walk on a treadmill at one mile per hour for two minutes, then walk/jog on the treadmill at three miles per hour for two minutes.\n",
    "\n",
    "Second Relaxation: five minutes.\n",
    "\n",
    "Mini-emotional stress*: 40 seconds (Note: This portion of the data, which was collected right before the cognitive stress task, is not explained in the paper.) During this 40 seconds, the “instructions” for the math portion of the cognitive stress (to count backwards by sevens, beginning with 2485, for three minutes) were read to the volunteer.\n",
    "\n",
    "Cognitive Stress: Count backwards by sevens, beginning with 2485, for three minutes. Next, perform the Stroop test for two minutes. The volunteer was alerted to errors by a buzzer. The Stroop test consisted of reading the names of colors written in a different color ink, then saying what color the ink was.\n",
    "\n",
    "Third Relaxation: five minutes.\n",
    "\n",
    "Emotional Stress: The volunteer was told he/she would be shown a five minute clip from a horror movie in one minute. After the minute of anticipation, a clip from a zombie apocalypse movie, The Horde was shown.\n",
    "\n",
    "Forth Relaxation: five minutes.\n",
    "\n",
    "*Note: We had not originally intended to count the reading of the instructions to count backwards as an emotional stress. After all, instructions were given for each of the tasks. Unlike the other instruction sets, however, this one created a stress response in many of the volunteers that was obvious to the test administrator as the test was being given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Each subject has several datafiles:\n",
    "- SubjectN_AccTempEDA.atr: annotation\n",
    "- SubjectN_AccTempEDA.dat: data\n",
    "- SubjectN_AccTempEDA.hea: header\n",
    "- SubjectN_Sp02HR.dat: data\n",
    "- SubjectN_Sp02HR.hea: header\n",
    "\n",
    "These files are in the WFDB (WaveForm DataBase) format, and can be read using the `wfdb` python module.\n",
    "(https://github.com/MIT-LCP/wfdb-python)\n",
    "\n",
    "https://www.physionet.org/standards/npsg/Moody.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "# pip install wfdb\n",
    "import wfdb\n",
    "\n",
    "# render plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acc Temp EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = wfdb.rdann('./data/physionet/Subject10_AccTempEDA', extension='atr', summarize_labels=True)\n",
    "print(ann.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_acc_temp_eda = wfdb.rdrecord('./data/physionet/Subject10_AccTempEDA')\n",
    "print(record_acc_temp_eda.__dict__)\n",
    "\n",
    "wfdb.plot_wfdb(record=record_acc_temp_eda, title='Subject10_AccTempEDA', annotation=ann, plot_sym=True, \n",
    "               time_units='seconds', figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_acc_temp_eda = record_acc_temp_eda.p_signal\n",
    "data_acc_temp_eda.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpO2 HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_spo2_hr = wfdb.rdrecord('./data/physionet/Subject10_SpO2HR')\n",
    "print(record_spo2_hr.__dict__)\n",
    "\n",
    "wfdb.plot_wfdb(record=record_spo2_hr, title='Subject10_SpO2HR', time_units='seconds', figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_spo2_hr = record_spo2_hr.p_signal\n",
    "data_spo2_hr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of acceleration, etc samples per second\n",
    "record_acc_temp_eda.fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of SpO2 and HR samples per second\n",
    "record_spo2_hr.fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning data of different frequencies\n",
    "\n",
    "The two dataset frequencies (number of samples per second) are different.\n",
    "\n",
    "To support processing both datasets at the same time, we need to match the frequencies.\n",
    "\n",
    "This is a common situation when taking readings from different sensors or data sources.\n",
    "\n",
    "Two strategies:\n",
    "1. Upsampling the smaller frequency data. E.g: repeat samples or interpolate.\n",
    "2. Downsampling the larger frequency data. E.g: replace with mean or median.\n",
    "\n",
    "Which one to pick depends on requirements: whether you need to maintain precision of the higher frequency dataset.\n",
    "\n",
    "Example: https://machinelearningmastery.com/resample-interpolate-time-series-data-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Upsampling SpO2 HR to 8 samples per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an index with 1 second timestamps, using the length of data_spo2_hr\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.period_range.html\n",
    "#\n",
    "# frequency strings: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "\n",
    "# for this dataset, the start date is just an arbitrary reference\n",
    "per_second_index = pd.period_range(start='2019-01-01', periods=len(data_spo2_hr), freq='S')\n",
    "per_second_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe for SpO2 data using the above period index\n",
    "df_spO2_hr = pd.DataFrame(data_spo2_hr, index=per_second_index, columns=record_spo2_hr.sig_name)\n",
    "df_spO2_hr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample to match the frequency of the other data (8 times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = record_acc_temp_eda.fs / record_spo2_hr.fs\n",
    "factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample, then interpolate\n",
    "# Note: whether interpolation makes sense depends on the sensor and type of data\n",
    "upsampled = df_spO2_hr.resample('125ms')\n",
    "\n",
    "df_upsampled = upsampled.interpolate()\n",
    "df_upsampled.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upsampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: there are fewer values in the Acc dataframe, so we need to ignore the\n",
    "# later entries from df_upsampled.\n",
    "\n",
    "df_acc_temp_eda = pd.DataFrame(data_acc_temp_eda, columns=record_acc_temp_eda.sig_name)\n",
    "df_acc_temp_eda.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_temp_eda.index = df_upsampled.index[:len(df_acc_temp_eda)]\n",
    "df_acc_temp_eda.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the two dataframes, column-wise\n",
    "df_option1 = pd.concat([df_acc_temp_eda, df_upsampled], axis=1).dropna()\n",
    "df_option1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_option1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/48126330/python-int-too-large-to-convert-to-c-long-plotting-pandas-dates\n",
    "df_option1.index = pd.to_datetime(df_option1.index.to_timestamp())\n",
    "\n",
    "df_option1.plot(figsize=(15, 10))\n",
    "ax = plt.gca()\n",
    "ax.set_title('Upsampled Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_option1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Downsampling Acc Temp EDA to 1 sample per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an index with 125 millisecond timestamps, using the length of data_acc_temp_eda\n",
    "#\n",
    "# frequency strings: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "\n",
    "# for this dataset, the start date is just an arbitrary reference\n",
    "per_125_ms_index = pd.period_range(start='2019-01-01', periods=len(data_acc_temp_eda), freq='125ms')\n",
    "per_125_ms_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe for Acc Temp EDA using the 125ms period index\n",
    "df_acc_temp_eda2 = pd.DataFrame(data_acc_temp_eda, index=per_125_ms_index, columns=record_acc_temp_eda.sig_name)\n",
    "df_acc_temp_eda2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample using median\n",
    "df_acc_temp_eda_downsampled = df_acc_temp_eda2.resample('S').median()\n",
    "df_acc_temp_eda_downsampled.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_temp_eda_downsampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spo2_hr2 = pd.DataFrame(data_spo2_hr, columns=record_spo2_hr.sig_name, index=per_second_index)\n",
    "df_spo2_hr2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the two dataframes, column-wise\n",
    "df_option2 = pd.concat([df_acc_temp_eda_downsampled, df_spo2_hr2], axis=1).dropna()\n",
    "df_option2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_option2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not needed, but for consistency with df_option1\n",
    "df_option2.index = pd.to_datetime(df_option2.index.to_timestamp())\n",
    "\n",
    "df_option2.plot(figsize=(15, 10))\n",
    "ax = plt.gca()\n",
    "ax.set_title('Downsampled Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's zoom into a 1-second time window and compare the plots\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(15, 10))\n",
    "start_time = '2019-01-01 00:05'\n",
    "end_time = '2019-01-01 00:06'\n",
    "\n",
    "df_option1[(df_option1.index >= start_time) & (df_option1.index < end_time)].plot(ax=ax1)\n",
    "ax1.set_title('Upsampled (with interpolation)')\n",
    "df_option2[(df_option2.index >= start_time) & (df_option2.index < end_time)].plot(ax=ax2)\n",
    "ax2.set_title('Downsampled (with median)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Features\n",
    "\n",
    "- Mean, median, standard deviation\n",
    "- Quantisation / discretisation\n",
    "- Correlation\n",
    "- Auto-correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_option1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean() # mean of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.median() # median is less sensitive to outliers than mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.std() # standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretise into quantiles\n",
    "\n",
    "Discretisation is useful when there is a lot of noise in the signal.\n",
    "\n",
    "https://datascience.stackexchange.com/questions/19782/what-is-the-rationale-for-discretization-of-continuous-features-and-when-should"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ax.values.ravel() # raw values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ax_q10'] = pd.qcut(df.ax.values.ravel(), 10, labels=False, duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "df['ax_q10'].plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram showing distribution in the 10 levels\n",
    "# Note: a histogram best applies to discrete variables\n",
    "df['ax_q10'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ay_q10'] = pd.qcut(df.ay.values.ravel(), 10, labels=False, duplicates='drop')\n",
    "df['az_q10'] = pd.qcut(df.az.values.ravel(), 10, labels=False, duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting multiple histograms\n",
    "df.loc[:, ['ax_q10', 'ay_q10', 'az_q10']].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pair-plot\n",
    "\n",
    "Pair plots are a combination of scatter plots and histograms. \n",
    "\n",
    "They are done for each pair of features (e.g. ax vs. ay)\n",
    "\n",
    "https://seaborn.pydata.org/generated/seaborn.pairplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "\n",
    "Correlations provide a metric to indicate whether two variables are strongly dependent.\n",
    "\n",
    "https://www.statisticssolutions.com/correlation-pearson-kendall-spearman/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.heatmap(df.corr(method='pearson'), annot=True, fmt='.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-correlation\n",
    "\n",
    "Runs correlation on progressive longer time steps (lags)\n",
    "\n",
    "https://machinelearningmastery.com/gentle-introduction-autocorrelation-partial-autocorrelation/\n",
    "\n",
    "The Pearson’s correlation coefficient is a number between -1 and 1 that describes a negative or positive correlation respectively. A value of zero indicates no correlation.\n",
    "\n",
    "We can calculate the correlation for time series observations with observations with previous time steps, called lags. Because the correlation of the time series observations is calculated with values of the same series at previous times, this is called a serial correlation, or an autocorrelation.\n",
    "\n",
    "Confidence intervals are drawn as a cone. By default, this is set to a 95% confidence interval, suggesting that correlation values outside of this code are very likely a correlation and not a statistical fluke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['ax', 'ay', 'az', 'SpO2', 'EDA', 'hr']\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, c in zip(axes, columns):\n",
    "    plot_acf(df[c], ax=ax)\n",
    "    ax.set_title(f'Autocorrelation: {c}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = 30\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "for ax, c in zip(axes, columns):\n",
    "    plot_acf(df[c], ax=ax, lags=lags)\n",
    "    ax.set_title(f'Autocorrelation: {c}, lags: {lags}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectal Features\n",
    "\n",
    "- FFT: https://ipython-books.github.io/101-analyzing-the-frequency-components-of-a-signal-with-a-fast-fourier-transform/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
