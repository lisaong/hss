{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Activity Classifier Workshop\n",
    "\n",
    "In this workshop, we will be training a classifier using body positions extracted from video.\n",
    "\n",
    "![photo](assets/istockphoto-476741742.jpg)\n",
    "\n",
    "This follows up from [04_pose_estimation.ipynb](04_pose_estimation.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import paired_distances\n",
    "\n",
    "# requires: conda install opencv\n",
    "import cv2\n",
    "\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keypoints_to_dataframe(keypoints):\n",
    "    \"\"\"Converts a flat keypoints list (x1, y1, c1, x2, y2, c2) into a pandas DataFrame\"\"\"\n",
    "    return pd.DataFrame({'x': keypoints[::3], 'y': keypoints[1::3], 'c': keypoints[2::3]})\n",
    "\n",
    "def get_centroid(coordinates, threshold=0.1):\n",
    "    \"\"\"Computes the centroid of a given 2 dimensional vector\"\"\"\n",
    "    x = coordinates[coordinates.c > threshold].x\n",
    "    y = coordinates[coordinates.c > threshold].y\n",
    "    \n",
    "    return [sum(x)/len(x), sum(y)/len(y)]\n",
    "\n",
    "def get_centroids(frame):\n",
    "    \"\"\"Returns the centroid for each person as a list of (x, y) coordinates\"\"\"\n",
    "    return np.array([get_centroid(keypoints_to_dataframe(person['pose_keypoints_2d'])) for person in frame['people']])\n",
    "\n",
    "def get_closest_index(centroid, other_frame):\n",
    "    \"\"\"Find closest index in other_frame from a given centroid\"\"\"\n",
    "    other_centroids = get_centroids(other_frame)\n",
    "    return np.argmin(paired_distances(np.ones(other_centroids.shape) * centroid, other_centroids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract keypoints from the videos using OpenPose\n",
    "\n",
    "1. Modify the paths under `HSS_DIR` and `OPENPOSE_DIR`.\n",
    "\n",
    "2. Run the code below which calls OpenPoseDemo to extract the keypoints from the data videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin\\OpenPoseDemo.exe --part_candidates --write_json D:\\S-HSS\\Workshop\\hss\\data\\dozing\\awake\\1 --video D:\\S-HSS\\Workshop\\hss\\data\\dozing\\awake\\1.avi         --frame_first 20 --frame_step 1 --frame_last 50\n",
      "bin\\OpenPoseDemo.exe --part_candidates --write_json D:\\S-HSS\\Workshop\\hss\\data\\dozing\\awake\\2 --video D:\\S-HSS\\Workshop\\hss\\data\\dozing\\awake\\2.avi         --frame_first 20 --frame_step 1 --frame_last 50\n",
      "bin\\OpenPoseDemo.exe --part_candidates --write_json D:\\S-HSS\\Workshop\\hss\\data\\dozing\\awake\\3 --video D:\\S-HSS\\Workshop\\hss\\data\\dozing\\awake\\3.avi         --frame_first 20 --frame_step 1 --frame_last 50\n",
      "bin\\OpenPoseDemo.exe --part_candidates --write_json D:\\S-HSS\\Workshop\\hss\\data\\dozing\\sleep\\1 --video D:\\S-HSS\\Workshop\\hss\\data\\dozing\\sleep\\1.avi         --frame_first 20 --frame_step 1 --frame_last 50\n",
      "bin\\OpenPoseDemo.exe --part_candidates --write_json D:\\S-HSS\\Workshop\\hss\\data\\dozing\\sleep\\2 --video D:\\S-HSS\\Workshop\\hss\\data\\dozing\\sleep\\2.avi         --frame_first 20 --frame_step 1 --frame_last 50\n",
      "bin\\OpenPoseDemo.exe --part_candidates --write_json D:\\S-HSS\\Workshop\\hss\\data\\dozing\\sleep\\3 --video D:\\S-HSS\\Workshop\\hss\\data\\dozing\\sleep\\3.avi         --frame_first 20 --frame_step 1 --frame_last 50\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "############# CHANGE BELOW PATH ################\n",
    "HSS_DIR=r'D:\\S-HSS\\Workshop\\hss'\n",
    "############# CHANGE ABOVE PATH ################\n",
    "\n",
    "############# CHANGE BELOW PATH ################\n",
    "OPENPOSE_DIR=r'D:\\S-HSS\\Workshop\\openpose-1.5.1-binaries-win64-only_cpu-python-flir-3d\\openpose'\n",
    "############# CHANGE ABOVE PATH ################\n",
    "\n",
    "classes = ['awake', 'sleep']\n",
    "\n",
    "cwd = os.getcwd()\n",
    "os.chdir(OPENPOSE_DIR)\n",
    "for c in classes:\n",
    "    data_path=os.path.join(HSS_DIR, r'data\\dozing', c)\n",
    "    files = glob.glob(os.path.join(data_path, '*.avi'))\n",
    "    \n",
    "    for f in files:\n",
    "        name, _ = f.split('.')\n",
    "        input_path=os.path.join(data_path, f)\n",
    "        output_path=os.path.join(data_path, name)\n",
    "\n",
    "        cmd = f'bin\\\\OpenPoseDemo.exe --part_candidates --write_json {output_path} --video {input_path} \\\n",
    "        --frame_first 20 --frame_step 1 --frame_last 50'\n",
    "        print(cmd)\n",
    "        os.system(cmd)\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
